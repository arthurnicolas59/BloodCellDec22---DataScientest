import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Paramètres du modèle
num_classes = 8
input_shape = (360, 363, 3)
batch_size = 32
height, width, color = input_shape

# mon dataframe 'df_image_et_masque' intègre les chemins d'accès aux images dans la colonne 'filepath',
# les chemins d'accès aux masques dans la colonne 'maskpath', et une colonne 'namLabel' correspondant à la classe de l'image

# Créer un générateur de données pour les images et les masques
datagen = ImageDataGenerator(rescale=1./255)  # Normalisation des pixels entre 0 et 1

def image_mask_generator(df, datagen, batch_size):
    image_generator = datagen.flow_from_dataframe(
        df,
        x_col='filepath',  # Colonne contenant les chemins d'accès aux images
        y_col='nameLabel',  # Colonne contenant les labels de classe
        target_size=(height, width),
        batch_size=batch_size,
        class_mode='categorical',  # Pour une classification multiclasse
        shuffle=True
    )

    mask_generator = datagen.flow_from_dataframe(
        df,
        x_col='maskpath',  # Colonne contenant les chemins d'accès aux masques
        y_col='nameLabel',  # Colonne contenant les labels de classe
        target_size=(height, width),
        batch_size=batch_size,
        class_mode='categorical',  # Pour une classification multiclasse
        shuffle=True
    )

    while True:
        images, labels = image_generator.next()
        masks, _ = mask_generator.next()  # Les masques n'ont pas besoin de labels

        yield [images, masks], labels

# Diviser le dataframe en ensembles d'entraînement, de validation et de test
train_df, test_df = train_test_split(df_image_et_masque, test_size=0.2, random_state=42)
train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)

# Créer les générateurs de données pour les ensembles d'entraînement, de validation et de test
train_generator = image_mask_generator(train_df, datagen, batch_size)
val_generator = image_mask_generator(val_df, datagen, batch_size)
test_generator = image_mask_generator(test_df, datagen, batch_size)

# Créer le modèle
image_input = layers.Input(shape=input_shape)
mask_input = layers.Input(shape=input_shape)
conv1 = layers.Conv2D(16, 3, padding='same', activation='relu')(image_input)
pool1 = layers.MaxPooling2D()(conv1)
conv2 = layers.Conv2D(32, 3, padding='same', activation='relu')(pool1)
pool2 = layers.MaxPooling2D()(conv2)
conv3 = layers.Conv2D(64, 3, padding='same', activation='relu')(pool2)
pool3 = layers.MaxPooling2D()(conv3)
flatten = layers.Flatten()(pool3)
dense1 = layers.Dense(128, activation='relu')(flatten)
output = layers.Dense(num_classes, activation='softmax')(dense1)

model_benchmark = models.Model(inputs=[image_input, mask_input], outputs=output)

# Compiler le modèle
model_benchmark.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Entraîner le modèle sur l'ensemble d'entraînement et valider sur l'ensemble de validation
model_benchmark.fit(train_generator, steps_per_epoch=len(train_df) // batch_size,
                    validation_data=val_generator, validation_steps=len(val_df) // batch_size,
                    epochs=10)

# Évaluer le modèle sur l'ensemble de test
test_loss, test_accuracy = model_benchmark.evaluate(test_generator, steps=len(test_df) // batch_size)
print(f"Test accuracy: {test_accuracy}")
